{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast 4\n",
    "nachdem mit einem Forecast gut läuft hier mal +4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mal wieder alles rein laden:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"data/bitcoin_short.csv\", index_col=1)\n",
    "    # df_val= Open Value\n",
    "    df_val = df.drop(columns='Close').drop(columns='High').drop(columns='Low')\n",
    "    #df_targ= CLose Value\n",
    "    df_targ = df.drop(columns='Open').drop(columns='High').drop(columns='Low')\n",
    "    return df, df_val, df_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teile DAten auf in 6 Teile verlauf und 4 Teile Forecast.\n",
    "# erstmal so ich werde mir das vll iterativ anschauen...\n",
    "def split_forecast(df_val):\n",
    "    data = df_val.values.reshape(-1,10)\n",
    "    new_dat= []\n",
    "    new_targ= [[]]\n",
    "    for dat in data:\n",
    "        new_dat = np.append(new_dat, dat[:-4])\n",
    "        new_targ = np.append(new_targ, dat[-4:])\n",
    "    new_dat = new_dat.reshape(-1,6)\n",
    "    new_targ = new_targ.reshape(-1,4)\n",
    "    print(\"new_dat: \", new_dat.shape)\n",
    "    print(\"new_targ: \", new_targ.shape)\n",
    "    return new_dat, new_targ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So hier wird der Datensatz sequentiell aufgeteilt\n",
    "def split_seq(df_val):\n",
    "    data = df_val.values\n",
    "    new_dat= []\n",
    "    new_targ= []\n",
    "    for i in range(len(data)-10):\n",
    "        new_dat = np.append(new_dat, data[i:i+6])\n",
    "        new_targ = np.append(new_targ, data[i+6:i+10])\n",
    "        \n",
    "    new_dat = new_dat.reshape(-1,6)\n",
    "    new_targ = new_targ.reshape(-1,4)\n",
    "    #print(new_dat.shape)\n",
    "    #print(new_targ.shape)\n",
    "    return new_dat, new_targ\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_val, df_targ = load_data()\n",
    "x_seq, y_seq = split_seq(df_val[:-(len(df_val)%10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9372.00000001 9379.99999997 9412.99999318 9420.03499994 9374.\n",
      " 9367.43814562]\n",
      "[9366.00059    9390.33978874 9371.00005511 9350.00000006]\n",
      "                   Open\n",
      "Timestamp              \n",
      "1517496900  9372.000000\n",
      "1517497500  9380.000000\n",
      "1517497800  9412.999993\n",
      "1517498100  9420.035000\n",
      "1517498400  9374.000000\n",
      "1517498700  9367.438146\n",
      "1517499000  9366.000590\n",
      "1517499300  9390.339789\n",
      "1517499600  9371.000055\n",
      "1517499900  9350.000000\n"
     ]
    }
   ],
   "source": [
    "#nur kurz zum Prüfen der Daten...\n",
    "print(x_seq[0])\n",
    "print(y_seq[0])\n",
    "print(df_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_dat:  (5125, 6)\n",
      "new_targ:  (5125, 4)\n"
     ]
    }
   ],
   "source": [
    "#Achtung wir brauchen Mod10 Daten => wir lassen Mod10 rest weg :)\n",
    "x_data, y_data = split_forecast(df_val[:-(len(df_val)%10)])\n",
    "#skalieren der Daten\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "data2 = min_max_scaler.fit_transform(x_seq)\n",
    "target2 = min_max_scaler.fit_transform(y_seq)\n",
    "#aufteieln in test und train\n",
    "x_train, x_test, y_train, y_test = train_test_split(data2, target2, random_state=23111, test_size=0.30)\n",
    "#datax und datay komplett\n",
    "datax = data2\n",
    "datay = target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
